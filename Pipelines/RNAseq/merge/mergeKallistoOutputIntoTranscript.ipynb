{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path+=['../']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import param\n",
    "from IPython.utils import io\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (5,6,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.1 s, sys: 3.96 s, total: 43 s\n",
      "Wall time: 40.2 s\n"
     ]
    }
   ],
   "source": [
    "%time sra_dump_df=pd.read_csv(param.full_meta_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if data is in SRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allProcessedFnames=pd.Series(os.listdir(param.count_out_dir),dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix_m=allProcessedFnames.str.contains('.abundance.tsv.gz$')\n",
    "processedRnaseqSrr=allProcessedFnames[postfix_m].str.split('.').str[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454926"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processedRnaseqSrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_dump_df['Skymap_TranscriptCount_Processed']=sra_dump_df['Run'].isin(processedRnaseqSrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_processed=sra_dump_df['Skymap_TranscriptCount_Processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select the species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faBaseDir='/cellar/users/btsui/Data/ensembl/release/cdna/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nProcess=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricToDtypeDict={'est_counts':np.uint32,'tpm':np.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "specieMetricPairs=list(product( param.supporting_species,metricToDtypeDict.keys()))\n",
    "#selectedSpecies="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homo_sapiens est_counts\n",
      "# of samples to merge: 192981\n",
      "n chunks: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1945/1945 [02:04<00:00, 15.67it/s]\n",
      "100%|██████████| 105/105 [00:08<00:00, 12.76it/s]\n",
      "100%|██████████| 677/677 [00:53<00:00, 12.69it/s]\n",
      "100%|██████████| 3422/3422 [03:59<00:00, 14.28it/s]\n",
      "100%|██████████| 305/305 [00:24<00:00, 12.41it/s]\n",
      "100%|██████████| 579/579 [00:46<00:00, 12.34it/s]\n",
      "100%|██████████| 321/321 [00:23<00:00, 13.61it/s]\n",
      "100%|██████████| 1384/1384 [01:29<00:00, 15.50it/s]\n",
      "100%|██████████| 2037/2037 [02:22<00:00, 14.34it/s]\n",
      "100%|██████████| 4881/4881 [05:18<00:00, 15.30it/s]\n",
      "100%|██████████| 3025/3025 [03:57<00:00, 12.75it/s]\n",
      "100%|██████████| 2491/2491 [02:51<00:00, 14.50it/s]\n",
      "100%|██████████| 670/670 [00:45<00:00, 14.85it/s]\n",
      "100%|██████████| 430/430 [00:29<00:00, 14.66it/s]\n",
      "100%|██████████| 392/392 [00:26<00:00, 14.95it/s]\n",
      "100%|██████████| 479/479 [00:29<00:00, 16.35it/s]\n",
      "100%|██████████| 625/625 [00:39<00:00, 15.74it/s]\n",
      "100%|██████████| 134/134 [00:10<00:00, 12.34it/s]\n",
      "100%|██████████| 388/388 [00:23<00:00, 16.50it/s]\n",
      "100%|██████████| 352/352 [00:24<00:00, 14.38it/s]\n",
      "100%|██████████| 590/590 [00:49<00:00, 11.96it/s]\n",
      "100%|██████████| 342/342 [00:25<00:00, 13.63it/s]\n",
      "100%|██████████| 567/567 [00:34<00:00, 16.57it/s]\n",
      "100%|██████████| 1082/1082 [01:20<00:00, 13.37it/s]\n",
      "100%|██████████| 434/434 [00:29<00:00, 14.89it/s]\n",
      "100%|██████████| 3046/3046 [03:27<00:00, 14.71it/s]\n",
      "100%|██████████| 2358/2358 [02:18<00:00, 17.08it/s]\n",
      "100%|██████████| 5302/5302 [04:58<00:00, 17.79it/s]\n",
      "100%|██████████| 801/801 [00:48<00:00, 16.42it/s]\n",
      "100%|██████████| 217/217 [00:14<00:00, 15.05it/s]\n",
      "100%|██████████| 2562/2562 [02:32<00:00, 16.85it/s]\n",
      "100%|██████████| 4497/4497 [04:50<00:00, 15.48it/s]\n",
      "100%|██████████| 2984/2984 [02:49<00:00, 17.61it/s]\n",
      "100%|██████████| 1612/1612 [01:31<00:00, 17.55it/s]\n",
      "100%|██████████| 4436/4436 [04:26<00:00, 16.66it/s]\n",
      "100%|██████████| 89/89 [00:07<00:00, 12.09it/s]\n",
      "100%|██████████| 5934/5934 [05:24<00:00, 18.31it/s]\n",
      "100%|██████████| 2300/2300 [02:14<00:00, 17.06it/s]\n",
      "100%|██████████| 499/499 [00:38<00:00, 13.06it/s]\n",
      "100%|██████████| 388/388 [00:25<00:00, 15.09it/s]\n",
      "100%|██████████| 676/676 [00:45<00:00, 14.90it/s]\n",
      "100%|██████████| 960/960 [01:08<00:00, 14.00it/s]\n",
      "100%|██████████| 325/325 [00:29<00:00, 11.05it/s]\n",
      "100%|██████████| 561/561 [00:47<00:00, 11.70it/s]\n",
      "100%|██████████| 560/560 [00:53<00:00, 10.39it/s]\n",
      "100%|██████████| 8575/8575 [08:36<00:00, 16.61it/s]\n",
      "100%|██████████| 1804/1804 [02:03<00:00, 14.56it/s]\n"
     ]
    }
   ],
   "source": [
    "#%%capture Stdout\n",
    "#selectedSpecies ,countMetric=('Canis_familiaris', 'tpm')  \n",
    "ignoreLastNDigitsForChunking=5\n",
    "for selectedSpecies ,countMetric in specieMetricPairs:\n",
    "    \n",
    "    #identify samples\n",
    "    print (selectedSpecies ,countMetric)\n",
    "    m_specie=sra_dump_df['new_ScientificName']==selectedSpecies\n",
    "    m=m_processed&m_specie\n",
    "    sra_dump_df_sub=sra_dump_df[m]\n",
    "    sra_dump_df_in=sra_dump_df_sub#.head(n=10)\n",
    "    nTotal=sra_dump_df_sub.shape[0]\n",
    "    print ('# of samples to merge:',nTotal)\n",
    "    inSrrs=sra_dump_df_in['Run'].unique()\n",
    "    ### identify the datatype in consideration. \n",
    "    myDtype=metricToDtypeDict[countMetric]\n",
    "\n",
    "    def parseOne(inSrr):\n",
    "        abundanceDir=param.count_out_dir+'{}.abundance.tsv.gz'.format(inSrr)\n",
    "        tmpDf=pd.read_csv(abundanceDir,sep='\\t')\n",
    "        tmpDf2=tmpDf.set_index('target_id')[countMetric].astype(myDtype)\n",
    "        return tmpDf2\n",
    "    #do the merge\n",
    "    inSrrS=pd.Series(inSrrs)\n",
    "    #each prefix is a Chunk ID\n",
    "    groupRunDf=pd.DataFrame({'Prefix':inSrrS.str[:-ignoreLastNDigitsForChunking],'Run':inSrrS})\n",
    "    print (\"n chunks:\",groupRunDf['Prefix'].nunique())\n",
    "    for Prefix,subRunS in groupRunDf.groupby('Prefix')['Run']:\n",
    "        with Pool(nProcess) as p:\n",
    "            myL=list(tqdm( p.imap(parseOne,subRunS),total=len(subRunS)))\n",
    "        #3 mins per chunk\n",
    "        mergedDf=pd.concat(myL,axis=1,keys=subRunS.values,copy=False)\n",
    "        outputDir='/nrnb/users/btsui/Data/all_seq/rnaseq_merged_chunks/{}.transcript.{}.{}.pickle'.format(\n",
    "            selectedSpecies,countMetric,Prefix)\n",
    "        mergedDf.to_pickle(outputDir)\n",
    "        del (mergedDf, myL)\n",
    "        gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -laht /nrnb/users/btsui/Data/all_seq/rnaseq_merged_chunks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
