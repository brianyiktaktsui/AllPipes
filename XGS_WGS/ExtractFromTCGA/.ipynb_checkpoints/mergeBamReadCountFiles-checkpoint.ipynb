{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lah /cellar/users/btsui/all_seq_snp/Homo_sapiens_all_merged_snp.pickle.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "## init\n",
    "mySpecie='Homo_sapiens'\n",
    "outMergedDir='/cellar/users/btsui/all_seq_snp/'+mySpecie+'_all_merged_snp.TCGA.prealigned.pickle'\n",
    "\n",
    "##change this dir to point to the updated csv\n",
    "#full_meta_dir=\"/cellar/users/btsui/Project/METAMAP/notebook/Parsing/sra_dump.csv\"\n",
    "inSrrDir='/nrnb/users/btsui/Data/tcga_extracted_lgg_snp_from_aligned_tcga_bam/'\n",
    "tmp_dir='/nrnb/users/btsui/Data/all_seq/tcga_tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lah /cellar/users/btsui/all_seq_snp/Homo_sapiens_all_merged_snp.TCGA.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -alh /nrnb/users/btsui/Data/tcga_extracted_lgg_snp/ |wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cellar/users/btsui/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpBedDf=pd.read_csv('/data/cellardata/users/btsui/dbsnp/snp_beds/'+mySpecie+'.bed',header=None,sep='\\t')\n",
    "unique_chroms=tmpBedDf[0].astype(np.str).unique()\n",
    "\n",
    "### start merging one by one \n",
    "if os.path.exists(tmp_dir):\n",
    "    os.system('rm -r '+tmp_dir)\n",
    "os.system('mkdir -p '+tmp_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_fname_postfix='.snp.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(tmp_dir)\n",
    "#identify non empty files\n",
    "os.system('ls -la '+inSrrDir+' > ls_out.txt ')\n",
    "ls_df=pd.read_csv('ls_out.txt',sep='\\s+',header=None,names=np.arange(9)).iloc[1:]\n",
    "#ls_df=\n",
    "size_S=ls_df[4]\n",
    "m4=size_S.astype(np.int)>1000\n",
    "m5=ls_df[8].str.contains(snp_fname_postfix+'$')\n",
    "non_empty_files=ls_df[m4&m5][8].str.split('/').str[-1].str.split('.').str[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmpBedDf.columns=['Chr','Pos','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmpBedDf['Pos'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nrows=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1% of the sites have data hitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "given: srr id \n",
    "return: the merged file\n",
    "\"\"\"\n",
    "\n",
    "### identify files to be merged\n",
    "fnames=pd.Series(os.listdir(inSrrDir))\n",
    "snpFnames=fnames[fnames.str.contains(snp_fname_postfix+'$')]\n",
    "srrsWithData=snpFnames.str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3=srrsWithData.isin(non_empty_files)\n",
    "toMergeSrrs=srrsWithData[m3].values\n",
    "TEST=False\n",
    "if TEST:\n",
    "    toRunSrrs=toMergeSrrs[:10]\n",
    "    chunkSize=5\n",
    "    nThread=1\n",
    "    nrows=10000\n",
    "else:\n",
    "    toRunSrrs=toMergeSrrs\n",
    "    chunkSize=10\n",
    "    nThread=8\n",
    "    nrows=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSrr(inSrr):\n",
    "    #print (inSrr)\n",
    "    fname=inSrrDir+inSrr+snp_fname_postfix\n",
    "    #print(fname)\n",
    "    tmpDf_all=pd.read_csv(fname,sep='\\s+',nrows=nrows,\n",
    "            header=None,names=np.arange(50),index_col=None,error_bad_lines=False)\n",
    "    #print (tmpDf_all.head())\n",
    "    \n",
    "    myCols=['Chr','Pos','Ref','rd_all','','A','C','G','T','N']\n",
    "    tmpDf=tmpDf_all.iloc[:,:len(myCols)]\n",
    "    tmpDf.columns=myCols\n",
    "    m_pos=tmpDf['Pos'].isin(tmpBedDf['Pos'])\n",
    "    #print (m_pos.mean())\n",
    "    tmpDf2=tmpDf[m_pos].set_index(['Chr','Pos'])\n",
    "    myBases=['A','C','G','T']\n",
    "    myL=[]\n",
    "    for base in myBases:\n",
    "            splitL=tmpDf2[base].str.split(':',expand=True)\n",
    "            ### extract  the read count and base quality\n",
    "            tmpDf5=splitL[[1,3]].astype(np.float)\n",
    "            tmpDf5.columns=['ReadDepth','AverageBaseQuality']\n",
    "            myL.append(tmpDf5)\n",
    "    tmpDf6=pd.concat(myL,keys=myBases,axis=0,names=['base'])\n",
    "    tmpDf6.columns.name='features'\n",
    "    mergedDf=tmpDf6.astype(np.uint16)\n",
    "    non_zero_df=mergedDf[mergedDf['ReadDepth']>0]\n",
    "    tmpDf7=non_zero_df.reset_index()\n",
    "    #Run_digits=re.search('[DES]RR(\\d+)', inSrr)\n",
    "    #Run_Db=re.search('([DES]RR)\\d+', inSrr)\n",
    "    tmpDf7['Run_digits']=inSrr\n",
    "    tmpDf7['Run_db']='TCGA'\n",
    "    ###convert the datatypes\n",
    "    tmpDf7['Pos']=tmpDf7['Pos'].astype(np.uint32)    \n",
    "    #tmpDf7['Run_digits']=tmpDf7['Run_digits'].astype(np.uint64)\n",
    "    tmpDf7['Chr']=tmpDf7['Chr'].str.replace('chr','')\n",
    "    #tmpDf7['Chr']=tmpDf7['Chr'].astype(np.str).astype('category',\n",
    "    #                                                  categories=unique_chroms,ordered=True)\n",
    "    #tmpDf7['Run_db']=tmpDf7['Run_db'].astype(np.str).astype('category',\n",
    "    #                                                        categories=['DRR','ERR','SRR'],ordered=True)\n",
    "    tmpDf7['base']=tmpDf7['base'].astype('category',\n",
    "                                         categories=myBases,ordered=True)\n",
    "    srr_pickle_df=tmpDf7.set_index(['Run_db','Run_digits',u'Chr', u'Pos',u'base']).sort_index()\n",
    "    return srr_pickle_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge each chunkSize amount of VCFs  among into different pickle chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optional: free up the memory\n",
    "#if not TEST:\n",
    "#    del mySpecieDf, full_meta_df\n",
    "\n",
    "def mergeSrrsL(i):\n",
    "    tmpL=[]\n",
    "    failedSrrsL=[]\n",
    "    for srr in toRunSrrs[i:(i+chunkSize)]:\n",
    "        ##try:\n",
    "        tmpL.append(parseSrr(srr))\n",
    "        #except :\n",
    "        #print ('failed: '+srr)\n",
    "        failedSrrsL.append(srr)\n",
    "    tmpMergedDf=pd.concat(tmpL)\n",
    "    #tmpMergedDf=pd.concat([parseSrr(srr) for srr in toRunSrrs[i:(i+chunkSize)]])\n",
    "    reorderedDf=tmpMergedDf.sort_index()\n",
    "    reorderedDf.to_pickle(tmp_dir+str(i)+'.pickle.gz',compression='gzip')\n",
    "    return failedSrrsL\n",
    "\n",
    "Chunks=np.arange(0, len(toRunSrrs),chunkSize)\n",
    "if TEST:\n",
    "    failed_srr_l=list(map(mergeSrrsL,Chunks.tolist()))\n",
    "else:\n",
    "    from multiprocessing import Pool\n",
    "    p=Pool(nThread)\n",
    "    ### sweep for uncompleted chunks\n",
    "    failed_srr_l=tqdm(list(p.imap(mergeSrrsL,Chunks.tolist())),total=len(toRunSrrs))\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myL=[]\n",
    "for fname in tqdm(os.listdir(tmp_dir)):\n",
    "    if '.pickle.gz' in fname:\n",
    "        myL.append(pd.read_pickle(tmp_dir+fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf=pd.concat(myL,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergedDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf.to_pickle(outMergedDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -lah /cellar/users/btsui/all_seq_snp/Homo_sapiens_all_merged_snp.TCGA.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outMergedDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
